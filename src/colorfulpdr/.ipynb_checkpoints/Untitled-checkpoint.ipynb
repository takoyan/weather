{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FeatureExtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合成加速度\n",
    "def get_SynAcc(x, y, z):\n",
    "    return math.sqrt(x*x + y*y + z*z)\n",
    "\n",
    "# 平均\n",
    "def get_ave(df):\n",
    "    stack_list=[]\n",
    "    for row in df.itertuples():\n",
    "        x, y, z=row[1], row[2], row[3]\n",
    "        stack_list.append(get_SynAcc(x, y, z))\n",
    "    return sum(stack_list)/len(stack_list)\n",
    "\n",
    "# 幅\n",
    "def get_Range(df):\n",
    "    stack_list=[]\n",
    "    for row in df.itertuples():\n",
    "        x, y, z=row[1], row[2], row[3]\n",
    "        stack_list.append(get_SynAcc(x, y, z))\n",
    "    return max(stack_list) - min(stack_list)\n",
    "\n",
    "# 標準偏差\n",
    "def get_Std(df):\n",
    "    stack_list=[]\n",
    "    ave=get_ave(df)\n",
    "    for row in df.itertuples():\n",
    "        syn=get_SynAcc(row[1], row[2], row[3])\n",
    "        stack_list.append((syn-ave)**2)\n",
    "    return math.sqrt(sum(stack_list)/(len(df)-1))\n",
    "\n",
    "# 歪度\n",
    "def get_Skewness(df):\n",
    "    stack_list=[]\n",
    "    ave=get_ave(df)\n",
    "    for row in df.itertuples():\n",
    "        syn=get_SynAcc(row[1], row[2], row[3])\n",
    "        stack_list.append((syn-ave)**3)\n",
    "    return sum(stack_list)/(get_Std(df)**3)*(len(df)/((len(df)-1)*(len(df)-2)))\n",
    "\n",
    "# 尖度\n",
    "def get_Kurtosis(df):\n",
    "    stack_list=[]\n",
    "    ave=get_ave(df)\n",
    "    for row in df.itertuples():\n",
    "        syn=get_SynAcc(row[1], row[2], row[3])\n",
    "        stack_list.append((syn-ave)**4)\n",
    "    return ((sum(stack_list)/(get_Std(df)**4))*((len(df)*(len(df)+1))/((len(df)-1)*(len(df)-2)*(len(df)-3)))) - (3*(len(df)-1)**2)/((len(df)-2)*(len(df)-3))\n",
    "\n",
    "# エネルギー\n",
    "def get_Energy(df):\n",
    "    stack_list=[]\n",
    "    for row in df.itertuples():\n",
    "        x, y, z=row[1], row[2], row[3]\n",
    "        stack_list.append(get_SynAcc(x, y, z)**2)\n",
    "    return sum(stack_list)\n",
    "\n",
    "def get_Fft(df):\n",
    "    stack_list=[]\n",
    "    for row in df_acc[0:3].itertuples():\n",
    "        x,y,z=row[1], row[2], row[3]\n",
    "        stack_list.append(get_SynAcc(x,y,z))\n",
    "    return max(np.fft.fft(stack_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm, metrics, preprocessing\n",
    "\n",
    "def checkAcuracy(df, user):\n",
    "    params = {\n",
    "        'loss_function': 'MultiClass',\n",
    "        'num_boost_round': 5000,\n",
    "        'early_stopping_rounds': 10,\n",
    "    }\n",
    "    warnings.simplefilter('ignore')\n",
    "    lr = LogisticRegression(random_state=0, max_iter=10000)\n",
    "\n",
    "    df_train=df[df['user']!='{}'.format(user)]\n",
    "    df_test=df[df['user']=='{}'.format(user)]\n",
    "    \n",
    "    x_train=df_train.drop(['label', 'user', 'index'], axis=1)\n",
    "    y_train=df_train[['index']]\n",
    "    x_test=df_test.drop(['label', 'user', 'index'], axis=1)\n",
    "    y_test=df_test[['index']]\n",
    "    \n",
    "    #model = CatBoost(params)\n",
    "    #model.fit(x_train, y_train)\n",
    "    #y_pred = model.predict(x_test, prediction_type='Probability')\n",
    "    #model = LogisticRegression(penalty='l2', random_state=0, max_iter=10000)\n",
    "    #model.fit(x_train, y_train)\n",
    "    model = svm.SVC(kernel='rbf', gamma=0.001, random_state=0, max_iter=10000)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred=model.predict(x_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print('user:'+user)\n",
    "    print(\"Accuracy:\"+str(acc))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    #return y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUND=1000\n",
    "\n",
    "for file in glob.glob(\"../../etc/label/*.csv\"):\n",
    "    # 同一ファイル内のすべてのcsvファイルの名前を取得\n",
    "    file_name=os.path.basename(file).split(\".csv\")[0]\n",
    "    new_df=pd.DataFrame() # 抽出後の特徴量格納用\n",
    "    label=pd.read_csv(\"../../etc/label/{}.csv\".format(file_name), header=None) # カラフルpdrようのラベルデータ取得\n",
    "    index=0\n",
    "    \n",
    "    # jsonをDataFrame型でload\n",
    "    df=pd.read_json(\"../../etc/no_header_pdr_raw_data/{}.json\".format(file_name), orient='records', lines=True)\n",
    "\n",
    "    print('{}LOAD DONE!!!!'.format(file_name))\n",
    "            \n",
    "    # ラベルのスタート時間から終了時刻までデータを取得\n",
    "    for i in range(label[0][0], label[0][len(label)-1]+1):\n",
    "        # ウィンドウ幅が1sなのでunixTimeを1000で割った商の部分で時刻を扱う\n",
    "        df_all=df[df['unixTime']//ROUND==((df['unixTime'].min()//ROUND)+i)]\n",
    "        df_acc=df_all[df_all['type']=='Accelerometer']\n",
    "        df_gyro=df_all[df_all['type']=='Gyroscope']\n",
    "        if len(df_acc)==0:\n",
    "            print('no Acc (time:{})'.format(i))\n",
    "            index+=1\n",
    "            continue\n",
    "    \n",
    "        if len(df_gyro)==0:\n",
    "            print('no Gyro (time:{})'.format(i))\n",
    "            index+=1\n",
    "            continue\n",
    "    \n",
    "        new_df=new_df.append({'label':label[1][index], 'user':file_name, 'acc_range':get_Range(df_acc), 'gyro_range':get_Range(df_gyro), \n",
    "                              'acc_std':get_Std(df_acc), 'gyro_std':get_Std(df_gyro), 'acc_skewness':get_Skewness(df_acc), \n",
    "                              'gyro_skewness':get_Skewness(df_gyro), 'acc_kurtosis':get_Kurtosis(df_acc), \n",
    "                              'gyro_kurtosis':get_Kurtosis(df_gyro), 'acc_energy':get_Energy(df_acc), 'gyro_energy':get_Energy(df_gyro), \n",
    "                              'acc_ave':get_ave(df_acc), 'gyro_ave':get_ave(df_gyro)}, \n",
    "                             ignore_index=True)\n",
    "        index+=1\n",
    "    new_df.to_csv(\"../../etc/test/{}.csv\".format(file_name), index=False) # ファイルの保存\n",
    "    print('{}DONE!!!!'.format(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['acc_ave', 'acc_energy', 'acc_kurtosis', 'acc_range', 'acc_skewness', 'acc_std', 'gyro_ave', 'gyro_energy', 'gyro_kurtosis', 'gyro_range', 'gyro_skewness', 'gyro_std']\n",
    "\n",
    "df_features=pd.read_csv('../../etc/test/clipped_raw_features.csv')\n",
    "x_train=df_features.drop(['label', 'user'], axis=1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "std_acc= sc.fit_transform(x_train)\n",
    "sc = StandardScaler()\n",
    "\n",
    "for column in columns:\n",
    "    print(stats.zscore(df_features[column].values))\n",
    "    df_features[column]=stats.zscore(df_features[column].values)\n",
    "\n",
    "df_features.to_csv('../../etc/test/clipped_std_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as oss\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, make_scorer, f1_score, recall_score\n",
    "\n",
    "import pydotplus, pprint\n",
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoost\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, metrics, preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'loss_function': 'MultiClass',\n",
    "        'num_boost_round': 5000,\n",
    "        'early_stopping_rounds': 10,\n",
    "    'silent': True\n",
    "    }\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "datas=pd.read_csv(\"../../etc/windows_features/clipped_std_features.csv\")\n",
    "df=datas[(datas['label']=='m') | (datas['label']=='s') | (datas['label']=='o')]\n",
    "df['index']=0\n",
    "df.loc[df['label']=='m', 'index']=1\n",
    "df.loc[df['label']=='s', 'index']=2\n",
    "df.loc[df['label']=='o', 'index']=3\n",
    "acc_sum=0\n",
    "file_names=[]\n",
    "accs=[]\n",
    "\n",
    "for file in glob.glob(\"../../etc/label/*.csv\"):\n",
    "    file_name=oss.path.basename(file).split(\".csv\")[0]\n",
    "\n",
    "    df_train=df[df['user']!='{}'.format(file_name)]\n",
    "    df_test=df[df['user']=='{}'.format(file_name)]\n",
    "    \n",
    "    x_train=df_train.drop(['label', 'user', 'index'], axis=1)\n",
    "    y_train=df_train[['index']]\n",
    "    x_test=df_test.drop(['label', 'user', 'index'], axis=1)\n",
    "    y_test=df_test[['index']]\n",
    "    \n",
    "    #model = CatBoost(params)\n",
    "    #model.fit(x_train, y_train)\n",
    "    model = LogisticRegression(penalty='l2', random_state=0, max_iter=10000)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred=model.predict(x_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    acc_sum+=acc\n",
    "    print(str(file_name)+':Accuracy:'+str(acc))\n",
    "    #file_names+=[file_name]\n",
    "    #accs+=[acc]\n",
    "    \n",
    "    #new_df=pd.DataFrame(y_pred, columns=['label'])\n",
    "    #new_df.to_csv('../../etc/pred_logi_label/{}.csv'.format(file_name), header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "\n",
    "datas=pd.read_csv(\"../../etc/windows_features/clipped_std_features.csv\")\n",
    "df=datas[(datas['label']=='m') | (datas['label']=='s') | (datas['label']=='o')]\n",
    "df['index']=0\n",
    "df.loc[df['label']=='m', 'index']=1\n",
    "df.loc[df['label']=='s', 'index']=2\n",
    "df.loc[df['label']=='o', 'index']=3\n",
    "\n",
    "for file in glob.glob(\"../../etc/label/*.csv\"):\n",
    "    file_name=oss.path.basename(file).split(\".csv\")[0]\n",
    "    checkAcuracy(df, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zip(p, a['index']):\n",
    "    if i[1]==2:\n",
    "        print(max(i[0])-i[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score in scores[-10:]:\n",
    "    checkAcuracy(df, score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for score in scores[:10]:\n",
    "    checkAcuracy(df, score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts=txt.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "d=defaultdict(float)\n",
    "for t in txts:\n",
    "    d[t.split(':')[0]]=float(t.split(':')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=sorted(d.items(), key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_sum/84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(accs)/len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_json(\"../../etc/no_header_pdr_raw_data/{}.json\".format('5NM4tiger'), orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['unixTime'][len(df[\"unixTime\"])-1]//1000)-(df['unixTime'][0]//1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'../../etc/noheader_pdr/5NM4tiger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unixTime'].tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['unixTime'][0]//1000)+285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1536130581971//1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
